{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"train_foo.csv\")\n",
    "dataset = np.array(data)\n",
    "np.random.shuffle(dataset)\n",
    "X = dataset\n",
    "Y = dataset\n",
    "X = X[:, 1:2501]\n",
    "Y = Y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[0:12000, :]\n",
    "X_train = X_train / 255.\n",
    "X_test = X[12000:13201, :]\n",
    "X_test = X_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "Y_train = Y[0:12000, :]\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y[12000:13201, :]\n",
    "Y_test = Y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 12000\n",
      "number of test examples = 1201\n",
      "X_train shape: (12000, 2500)\n",
      "Y_train shape: (1, 12000)\n",
      "X_test shape: (1201, 2500)\n",
      "Y_test shape: (1, 1201)\n"
     ]
    }
   ],
   "source": [
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (12000, 50, 50, 1)\n",
      "X_test shape: (1201, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "image_x = 50\n",
    "image_y = 50\n",
    "    \n",
    "train_y = np_utils.to_categorical(Y_train)\n",
    "test_y = np_utils.to_categorical(Y_test)\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 12000\n",
      "number of test examples = 1201\n",
      "X_train shape: (12000, 2500)\n",
      "Y_train shape: (1, 12000)\n",
      "X_test shape: (1201, 2500)\n",
      "Y_test shape: (1, 1201)\n",
      "X_train shape: (12000, 50, 50, 1)\n",
      "X_test shape: (1201, 50, 50, 1)\n",
      "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Train on 12000 samples, validate on 1201 samples\n",
      "Epoch 1/10\n",
      "12000/12000 [==============================] - 25s 2ms/step - loss: nan - accuracy: 0.6628 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 2/10\n",
      "   64/12000 [..............................] - ETA: 21s - loss: nan - accuracy: 0.5625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda\\envs\\Conda\\lib\\site-packages\\keras\\callbacks\\callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000/12000 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 3/10\n",
      "12000/12000 [==============================] - 25s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 4/10\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 5/10\n",
      "12000/12000 [==============================] - 25s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 6/10\n",
      "12000/12000 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 7/10\n",
      "12000/12000 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 8/10\n",
      "12000/12000 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 9/10\n",
      "12000/12000 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "Epoch 10/10\n",
      "12000/12000 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.6656 - val_loss: nan - val_accuracy: 0.6520\n",
      "CNN Error: 34.80%\n"
     ]
    }
   ],
   "source": [
    "data= pd.read_csv(\"train_foo.csv\")\n",
    "dataset = np.array(data)\n",
    "np.random.shuffle(dataset)\n",
    "X = dataset\n",
    "Y = dataset\n",
    "X = X[:, 1:2501]\n",
    "Y = Y[:, 0]\n",
    "\n",
    "X_train = X[0:12000, :]\n",
    "X_train = X_train / 255.\n",
    "X_test = X[12000:13201, :]\n",
    "X_test = X_test / 255.\n",
    "\n",
    "# Reshape\n",
    "Y = Y.reshape(Y.shape[0], 1)\n",
    "Y_train = Y[0:12000, :]\n",
    "Y_train = Y_train.T\n",
    "Y_test = Y[12000:13201, :]\n",
    "Y_test = Y_test.T\n",
    "\n",
    "print(\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print(\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"Y_train shape: \" + str(Y_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "print(\"Y_test shape: \" + str(Y_test.shape))\n",
    "image_x = 50\n",
    "image_y = 50\n",
    "\n",
    "train_y = np_utils.to_categorical(Y_train)\n",
    "test_y = np_utils.to_categorical(Y_test)\n",
    "train_y = train_y.reshape(train_y.shape[1], train_y.shape[2])\n",
    "test_y = test_y.reshape(test_y.shape[1], test_y.shape[2])\n",
    "X_train = X_train.reshape(X_train.shape[0], 50, 50, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 50, 50, 1)\n",
    "print(\"X_train shape: \" + str(X_train.shape))\n",
    "print(\"X_test shape: \" + str(X_test.shape))\n",
    "\n",
    "def keras_model(image_x, image_y):\n",
    "    num_of_classes = 12\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(image_x, image_y, 1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5), strides=(5, 5), padding='same'))\n",
    "    model.add(Conv2D(128,(2,2),activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5,5),strides=(5,5),padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(num_of_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    filepath = \"handEmo.h5\"\n",
    "    checkpoint1 = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint1]\n",
    "    return model, callbacks_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model, callbacks_list = keras_model(image_x, image_y)\n",
    "model.fit(X_train, train_y, validation_data=(X_test, test_y), epochs=10, batch_size=64,\n",
    "          callbacks=callbacks_list)\n",
    "scores = model.evaluate(X_test, test_y, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100 - scores[1] * 100))\n",
    "\n",
    "model.save('emojinator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
